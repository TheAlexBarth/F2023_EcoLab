---
title: Some approaches analyze lab 3
---

As we covered in our in-class lab analysis, there is no one correct way to analyze a complex dataset like the one that we have in our lab 3. However, I'll share my approaches here.

# Some Context

Let's return to the lab's hypotheses:

(H1): Along a strong, but short, moisture gradient the dominant tree species will vary in distinct regions.
(H2.A): Trees alter the soil composition at a hyper-local scale, so that their leaf-litter supports distinct
communities of invertebrates.
(H2.B): Alternative to H2.A, it could simply be that the abiotic factors are the primary factor determining
soil community structure, and the community will vary based on the soil characteristics rather than treespecies.

So for the first hypothesis, we want to evaluate if the dominance of different trees varies along the hillside. To assess "dominance" of trees, we can use the relative importance index and compare how it changes for different trees along the slope.

The second hypothesis is a little more complicated. We are simply interested if there is *some* difference in community composition between (A) particular trees vs open areas vs others or (B) between soil characteristics (which we assume are associated with the region). Thus, our first hypothesis is someone dependent on the results of the first hypothesis. If the tree community composition varies along the hill side then we'll only be able to compare . However, if tree dominance doesn't vary with the slope, we can assess soil community based on the tree-base and the soil community separately.

One general concern I had for this data analysis was that the wasn't really a true "open" area from which we could collect. The tree canopy covers the entire slopeside so we can't just compare tree vs. non-tree. However, if trees are different based on regions of the slope, we can still assess if the community composition is different. Another challenge of this lab is we have relatively small samples sizes for the transects. However we do have good data for the inverts.

My approach to analyze the data is very exploratory, I try a bunch of possible approaches to see if we can tease out a signal. However, as you'll see, analyses are just a tool - while some may be more useful in a given case, generally if there truly isn't a pattern - your data will show it!

For all this, I'm am using a few more advanced approaches to make it quicker. I'll show clearly how to run a simple version, but there's also the advanced options for those of you interested in some of the more powerful applications of R.

```{r, echo = F}
source('./utils.R')
library(dplyr)
library(ggplot2)
library(tidyr)

```

::: panel-tabset
#### Simple

In a simple approach, we read in our data by downloading from the github repo's data folder, put it in our folder of choice, then read it in locally (this is what I've taught so far):

```{r, echo = TRUE, eval=FALSE}
inverts <- read.csv('inverts.csv')
tree_raw <- read.csv('tree_raw.csv')
```

#### Adv.

What I actually do when writing the tutorials is I will read in the files directly from the internet. You can give read.csv an html address with a csv file. These can be found by clicking "raw" on the github page when looking at the csv of the data. That normally would look like this:

```{r, echo=T,eval=FALSE}
inverts <- read.csv("https://raw.githubusercontent.com/USC-Ecology-Lab/Lab_3_Community-Assemblages/main/data/inverts.csv")
```

However, because we have multiple files, I could click through and manually copy all links, but that's less fun. So I decided to try and figure out how to get all links automatically using githubs API. Now, this took longer to learn how to do than it would've to just copy-and-paste. But I had fun learning this for the past 10mins. Admittedly this is way more than just the 'advanced version', but you clicked on this tab so ha.

Thanks chatGPT for the framework!

```{r, message=FALSE}
# This is the code that actually got ran

# I need R's api and json libraries
library(httr)
library(jsonlite)

repo <- 'usc-ecology-lab/Lab_3_Community-Assemblages'
folder_path <- './data'

api_url <- paste0("https://api.github.com/repos/", repo, "/contents/", folder_path)

# read it all in
response <- GET(api_url) |> 
  content('text') |> 
  fromJSON()

file_names <- response$name |> 
  gsub(pattern = '.csv',
       replacement = "",
       )

# now I can create a list of dataframe
df_list <- list()
# loop through and download
for(i in 1:nrow(response)) {
  df_list[[i]] <- read.csv(response$download_url[i])
}
names(df_list) <- file_names #name the list
list2env(df_list, envir = .GlobalEnv) #load the list to the environment
rm(list = c("df_list", "repo", "folder", "api_url",
            'file_names','folder_path','i'))
```
:::

# Exploratory Data Analysis for Trees

To address the first hypothesis, we need to explore how the importance of trees varies with the slope. However, to do this we need to think about the data we have.

The `tree_raw` dataframe does not offer much to work with. Unless we wanted to investigate a question like "does loblolly size vary based on slope?". Instead we need to rely on the RIV (relative importance value). I already calculated this for you in a few approaches. First, I did it by species and by category (grouping some similar species together). I also calculated RIV in 5m bins and then again in 3-large bins which correspond to the defined sub regions people listed on their transects.

RIV is calculated by effectively measuring the total area in a set bin which is occupied by that particular species. Such that for each $s$ species, and $i$ tree (belonging to a $s$ species):

$$
RIV_{s} = \frac{\sum_{i_s} \pi \frac{DBH_{i_s}}{2}^2}{\sum_{i} \pi \frac{DBH_{i}}{2}^2}
$$

### An attempt at regression

I really wanted to try a correlation/regression analysis in this lab. However, the data don't really make it all that clean (or appropriate). Nonetheless, I figured if I make 5-m bins we can try to treat them as a continuous variable and run a regression. The problem is that the tree observations are so sparse that there just isn't enough data.

::: panel-tabset
#### Simple

We can only look at one tree's RIV change at a time. For the simple example, let's just do hardwoods because they are the most abundant overall

```{r}
library(dplyr)
hardwood_bins <- tree_cat_5m |> 
  filter(Tree_cat == 'hardwood')

hardwood_lm <- lm(riv ~ bin, data = tree_cat_5m)
summary(hardwood_lm)
```

From the above output, we can look at the p-value of "bin" to see if there is a signficant effect of bin (slope location) on riv. It is 0.471, so we would conclude the slope is not significantly different from 0. Or in simpler words there is no effect.

To be quick, I just looked at this data using base R:

```{r}
plot(riv ~ bin, hardwood_bins)
abline(hardwood_lm)
```

This isn't a pretty plot I would present, but it is useful for my purposes.

To do this with other categories, you can just change where we filter for hardwoods and try for other categories!

#### Adv.

Really, in fully data exploration mode, I want to run the simple analysis for every single species and every single categories. It gets fairly messy to do this "by-hand" and copy-pasting code over and over and changing little details. Instead what I really would do here is loop through all categories and print out the regression output and make quick, ugly plots. If there's something interesting, I can clean it up later.

I can now scroll through all this output and read what I want!

```{r}
# Loop analysis:
tree_sp <- list()
for(tree in unique(tree_sp_riv_5m$tree_id)) {
  tree_sp[[tree]] <- tree_sp_riv_5m |> 
    filter(tree_id == tree)
}

# run the regressions here
tree_5m_reg_mod <- list()
for(tree in names(tree_sp)) {
  tree_5m_reg_mod[[tree]] <- lm(riv ~ bin, data = tree_sp[[tree]])
  print(tree) # print out name of trees
  print(summary(tree_5m_reg_mod[[tree]]))
}

for(tree in names(tree_sp)) {
  try({
    plot(riv ~ bin, tree_sp[[tree]],
         main = tree)
    abline(tree_5m_reg_mod[[tree]])
  })
}

```

I can also do this by category:

```{r}
# Loop analysis:
tree_cat <- list()
for(cat in unique(tree_cat_5m$Tree_cat)) {
  tree_cat[[cat]] <- tree_cat_5m |> 
    filter(Tree_cat == cat)
}

tree_cat_reg_mod <- list()
for(cat in names(tree_cat)) {
  tree_cat_reg_mod[[cat]] <- lm(riv ~ bin, data = tree_cat[[cat]])
  print(cat)
  print(summary(tree_cat_reg_mod[[cat]]))
}

for(cat in names(tree_cat)) {
  try({
    plot(riv ~ bin, tree_cat[[cat]],
         main = cat)
    abline(tree_cat_reg_mod[[cat]])
  })
}

```

Again in all these cases we just don't have enough data or any semblance of a trend to make a conclusion.
:::

### The Kruskall-Wallace approach

Since we don't really have enough data for a regression, the alternative approach is to use an ANOVA with RIV as the response variable and subregion as the predictor. Since we have a RIV value for each tree, we will need to run the ANOVA for each response variable. I'm not even investigating my assumptions for an ANOVA however because I have such small sample size, I'm going to assume that the non-parametric approach is necessary

I can make one graph to show all this data, but then run multiple tests to investigate the data.

::: panel-tabset
#### Plot

I'll just do this for groups by category since we already well know that there is not enough data for grouping by species.

```{r, echo=TRUE, eval=FALSE}
library(ggplot2)

tree_cat_summary <- tree_cat_subregion |> 
  group_by(Subregion, Tree_cat) |> 
  summarize(mean_riv = mean(riv),
            sd_riv = sd(riv))

ggplot(tree_cat_summary) +
  geom_bar(aes(x = Tree_cat, y = mean_riv, fill = Subregion),
           stat = 'identity', position = 'dodge') +
  geom_errorbar(aes(x = Tree_cat, ymin = mean_riv,
                    ymax = mean_riv + sd_riv,
                    color = Subregion),
                stat = 'identity', position = 'dodge') +
  labs(x = 'Tree Category', y = 'RIV', fill = "Subregion",
       color = "Subregion") +
  theme_classic()
```

```{r, echo=FALSE, message=FALSE}
library(ggplot2)

tree_cat_summary <- tree_cat_subregion |> 
  group_by(Subregion, Tree_cat) |> 
  summarize(mean_riv = mean(riv),
            sd_riv = sd(riv))

p1 = ggplot(tree_cat_summary) +
  geom_bar(aes(x = Tree_cat, y = mean_riv, fill = Subregion),
           stat = 'identity', position = 'dodge') +
  geom_errorbar(aes(x = Tree_cat, ymin = mean_riv,
                    ymax = mean_riv + sd_riv,
                    color = Subregion),
                stat = 'identity', position = 'dodge') +
  labs(x = 'Tree Category', y = 'RIV', fill = "Subregion",
       color = "Subregion") +
  theme_classic()
watermark_plot(p1)
```

#### Simple

#### Adv.
:::

# Exploratory Data Analysis for inverts
